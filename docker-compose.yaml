version: '3.1'

services:
    # Grafana Service
    grafana:
        image: grafana/grafana:6.5.0
        container_name: grafana
        restart: unless-stopped
        ports:
            - 3000:3000
        env_file:
            - ./Grafana/login_config
        volumes:
            - ./Grafana/grafana_db:/var/lib/grafana:rw #needs command 'sudo chmod -R 777 Grafana/*'
            - ./Grafana/provisioning/datasource:/etc/grafana/provisioning/datasources
            - ./Grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards 
        depends_on:
            - prometheus
    
    # Prometheus Service   
    prometheus:
        image: prom/prometheus:v2.20.1
        container_name: prometheus
        restart: unless-stopped
        ports: 
            - 9090:9090
        expose:
            - 9090
        command:
            - '--config.file=/etc/prometheus/prometheus.yml'
        volumes:
            - ./Prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
            - ./Prometheus/prometheus_db:/prometheus/data:rw #needs command 'sudo chmod -R 777 Prometheus/prometheus_db'
        depends_on:
            - node-exporter
            - cadvisor

    # Node-Exporter Service  
    node-exporter:
        image: prom/node-exporter:v1.0.1
        container_name: node-exporter
        ports:
            - 9100:9100
        restart: unless-stopped

    # Cadvisor Service 
    cadvisor:
        image: google/cadvisor:v0.33.0
        container_name: cadvisor
        restart:  unless-stopped
        ports:
            - 9080:8080
        volumes:
            - /:/rootfs:ro
            - /var/run:/var/run:rw
            - /sys:/sys:ro
            - /var/lib/docker/:/var/lib/docker:ro
        privileged: true

    # Spark
    spark-master:
        build:
            context: ./Spark
            dockerfile: Dockerfile
        container_name: master
        hostname: master
        ports:
            - 8080:8080
            - 8081:8081
            - 7077:7077
            - 4040:4040
            - 50070:50070 #Hadoop
            #- '22:22' # ??
        environment:
            - PYTHONUNBUFFERED=1
            - "HDFS_NAMENODE_USER=root"
            - "HDFS_DATANODE_USER=root"
            - "HDFS_SECONDARYNAMENODE_USER=root"
